{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3swoRe-8XUH",
        "outputId": "d5bf4bc9-0a43-41a8-9a4f-408dadb900b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('Tolerblanc/klue-bert-finetuned')\n",
        "model = TFBertForSequenceClassification.from_pretrained('Tolerblanc/klue-bert-finetuned', output_attentions=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvOaCS-3YMGl",
        "outputId": "ada835c5-d2ad-45ea-8387-5a0c41047859"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--Tolerblanc--klue-bert-finetuned/snapshots/0bf8dc4eefb6ab60b25f02cf3568deb6f23652af/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Tolerblanc--klue-bert-finetuned/snapshots/0bf8dc4eefb6ab60b25f02cf3568deb6f23652af/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--Tolerblanc--klue-bert-finetuned/snapshots/0bf8dc4eefb6ab60b25f02cf3568deb6f23652af/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Tolerblanc--klue-bert-finetuned/snapshots/0bf8dc4eefb6ab60b25f02cf3568deb6f23652af/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Tolerblanc--klue-bert-finetuned/snapshots/0bf8dc4eefb6ab60b25f02cf3568deb6f23652af/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"klue/bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.29.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file tf_model.h5 from cache at /root/.cache/huggingface/hub/models--Tolerblanc--klue-bert-finetuned/snapshots/0bf8dc4eefb6ab60b25f02cf3568deb6f23652af/tf_model.h5\n",
            "Some layers from the model checkpoint at Tolerblanc/klue-bert-finetuned were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at Tolerblanc/klue-bert-finetuned.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_classifier = TextClassificationPipeline(\n",
        "    tokenizer=tokenizer, \n",
        "    model=model, \n",
        "    framework='tf',\n",
        "    return_all_scores=True,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "3lbceru_1C5V"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **마스킹하는 함수**"
      ],
      "metadata": {
        "id": "A1MemmiD8eJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hate_expression(text_classifier, tokenizer, model,text):\n",
        "  output = text_classifier(text)[0]\n",
        "  clean = output[0]['score']\n",
        "  curse = output[1]['score']\n",
        "  print(f'{text} 가 입력되었으며,')\n",
        "  if clean > curse:\n",
        "    print(f'모델은 이 문장을 {clean * 100}% 확률로 깨끗한 문장이라고 추론했습니다.')\n",
        "    return text\n",
        "  else:\n",
        "    print(f'모델은 이 문장을 {curse * 100}% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.')\n",
        "    #문장을 단어단위로 분류\n",
        "    words = text.split()\n",
        "    masked_words = []\n",
        "\n",
        "    for word in words:\n",
        "        #wordpice토큰화를 진행하고, 텍스트를 정수 배열 변환\n",
        "        inputs = tokenizer.encode_plus(word, return_tensors=\"tf\")\n",
        "        \n",
        "        #하나의 문장만 사용해서 [0]으로 표현\n",
        "        outputs = model(inputs)[0] \n",
        "\n",
        "        #정규화시키고,  일반 표현과 혐오표현에 대한 각각의 확률값을 배열로 표현 \n",
        "        probabilities = tf.nn.softmax(outputs, axis=-1)\n",
        "\n",
        "        #혐오표현과 일반표현의 확률이 너무 낮은 경우 임계값 설정\n",
        "        threshold = 0.07514262                      \n",
        "        if probabilities.numpy()[0, 1] > threshold:\n",
        "          label_predictions = 1\n",
        "        else:\n",
        "          #확률값이 높은 부분의 위치를 숫자로 표현(일반표현 0, 혐오표현 1)\n",
        "          label_predictions = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "\n",
        "        # 0: 일반, 1: 혐오\n",
        "        if label_predictions ==1:\n",
        "            masked_word = \"*\" * len(word)\n",
        "            masked_words.append(masked_word)\n",
        "        else:\n",
        "            masked_words.append(word)\n",
        "\n",
        "    masked_text = \" \".join(masked_words)\n",
        "    return masked_text"
      ],
      "metadata": {
        "id": "2Nkxx36j1rmV"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '저게 시대적언어면 한남충도 시대적언어 아니노 ㅋㅋ\t'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56AizbBCS_u9",
        "outputId": "60e15c1a-8a70-43bb-e91c-e145c8a035e3"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저게 시대적언어면 한남충도 시대적언어 아니노 ㅋㅋ\t 가 입력되었으며,\n",
            "모델은 이 문장을 99.55450296401978% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "저게 시대적언어면 **** 시대적언어 아니노 ㅋㅋ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '배고픈데 앞에서 만두 먹네 개시키'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWvDtJNsT5zW",
        "outputId": "e566de90-ea9e-4d3a-f2e0-3c76d53b0295"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "배고픈데 앞에서 만두 먹네 개시키 가 입력되었으며,\n",
            "모델은 이 문장을 99.68923926353455% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "배고픈데 앞에서 만두 먹네 ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'ㅅㅂ'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccEBmREClADV",
        "outputId": "b307a2bd-9218-45e2-88b9-ea8af112d8df"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ㅅㅂ 가 입력되었으며,\n",
            "모델은 이 문장을 88.87845277786255% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-mdGjLflDcp",
        "outputId": "5ce0bffd-3aeb-4ce4-9bb1-47146c9c5254"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나 가 입력되었으며,\n",
            "모델은 이 문장을 99.95373487472534% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "마 *** 아 몇평이고 맷개드갔노 니 ****** ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '좌배 까는건 ㅇㅂ'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2oNjgkClPXm",
        "outputId": "6b23684e-0f80-420e-ce29-2e1ffe18a0b6"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "좌배 까는건 ㅇㅂ 가 입력되었으며,\n",
            "모델은 이 문장을 71.53672575950623% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "좌배 *** **\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '오마쥬가 뭔진 앎?'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ-59lQ-x_OH",
        "outputId": "1bc4fd45-9064-4f27-8309-dd3bde228222"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오마쥬가 뭔진 앎? 가 입력되었으며,\n",
            "모델은 이 문장을 99.93797540664673% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "오마쥬가 뭔진 앎?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='크로캅이 본야스키 개털던거 생각나네 ㅋㅋㅋㅋㅋㅋ진짜 개잡듯 잡아팼지 ㅋㅋㅋㅋ전직 은행원 본야스키 ㅋ'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-inrhWyAV-",
        "outputId": "cf3719b3-5caf-4698-c99b-a7c37ce5a1be"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "크로캅이 본야스키 개털던거 생각나네 ㅋㅋㅋㅋㅋㅋ진짜 개잡듯 잡아팼지 ㅋㅋㅋㅋ전직 은행원 본야스키 ㅋ 가 입력되었으며,\n",
            "모델은 이 문장을 94.540935754776% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='무게치는거에 인생버린새끼들'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ECIIQIyOJy",
        "outputId": "1bc5c14d-b69a-4c38-b7a4-bb36f7be06aa"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "무게치는거에 인생버린새끼들 가 입력되었으며,\n",
            "모델은 이 문장을 99.88462924957275% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "무게치는거에 *******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='버러지들'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvmjhTqryebU",
        "outputId": "568f2399-7e91-4e3e-c430-b5f7dcc87e4d"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버러지들 가 입력되었으며,\n",
            "모델은 이 문장을 79.22764420509338% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='창렬이노'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGG-ocFfynlT",
        "outputId": "18f5221e-ba43-4a69-e0b1-780600c79855"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "창렬이노 가 입력되었으며,\n",
            "모델은 이 문장을 99.96140599250793% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 병신새끼야.'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEb4z7MC4jsO",
        "outputId": "dddcd85a-ab98-412d-ac29-9ac92ba5c0c2"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 병신새끼야. 가 입력되었으며,\n",
            "모델은 이 문장을 99.95182752609253% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 *** 월급 못받고 굶어 *** 돼 ******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='강철멘탈이네...대한민국에 성매매 종사자가 수만 수십만인데 그걸 이용하는 남자는 수십배는 되지 않겟냐? 다 먹고 살고 있는거 보면 아닌척 하는 넘들이 가증스러운거지'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYQN6nWf62Pa",
        "outputId": "bad30302-eb77-4f2e-ef34-aee7f654852a"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "강철멘탈이네...대한민국에 성매매 종사자가 수만 수십만인데 그걸 이용하는 남자는 수십배는 되지 않겟냐? 다 먹고 살고 있는거 보면 아닌척 하는 넘들이 가증스러운거지 가 입력되었으며,\n",
            "모델은 이 문장을 94.25874352455139% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이ㅂㅅ은 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 버러지같은새키'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm_BoAg6XgZv",
        "outputId": "23779536-50eb-4c80-9e17-89aa050beec6"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이ㅂㅅ은 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 버러지같은새키 가 입력되었으며,\n",
            "모델은 이 문장을 99.95836615562439% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "**** 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 *******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='문빈은 너무 착하고 여려 혼자 맘고생 하다가 떠나고 패배는 정신승리 하면서 출소기념 소주병 퍼포먼스 이게 맞나'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4EDG6XIXrgZ",
        "outputId": "82a9bdd8-3323-47ca-b139-45b511788fea"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문빈은 너무 착하고 여려 혼자 맘고생 하다가 떠나고 패배는 정신승리 하면서 출소기념 소주병 퍼포먼스 이게 맞나 가 입력되었으며,\n",
            "모델은 이 문장을 99.60590600967407% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='나라 생긴지 몇 년 됐다고 저런 전통도 있었냐 ㅋㅋ ㅂㄹㅈ ㅋㅋㅋ'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBN7hGnUbka0",
        "outputId": "a4109895-389e-4a66-a1ed-b96f8a92f0c6"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나라 생긴지 몇 년 됐다고 저런 전통도 있었냐 ㅋㅋ ㅂㄹㅈ ㅋㅋㅋ 가 입력되었으며,\n",
            "모델은 이 문장을 88.39884996414185% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "나라 *** 몇 * 됐다고 저런 전통도 있었냐 ㅋㅋ *** ㅋㅋㅋ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='니넨얼마나잘살아왔냐ㅋㅋ 열등감오지네'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdE-Hr6Ge6Q6",
        "outputId": "6ee8ab31-2cda-4614-9bc0-2957cba33106"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "니넨얼마나잘살아왔냐ㅋㅋ 열등감오지네 가 입력되었으며,\n",
            "모델은 이 문장을 97.36399054527283% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "니넨얼마나잘살아왔냐ㅋㅋ ******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이새키보소'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqGWUFXXmCeJ",
        "outputId": "07282454-4ce9-4134-d373-92094860d01c"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이새키보소 가 입력되었으며,\n",
            "모델은 이 문장을 99.84443783760071% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "*****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='쓰레기는 변하지 않아~'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hyLXj9dm2fK",
        "outputId": "4632b3f8-9bd4-4fac-a86e-cb568cdd6945"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "쓰레기는 변하지 않아~ 가 입력되었으며,\n",
            "모델은 이 문장을 99.90399479866028% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='요목조목 다 따져봐도 특출나게 잘난것도 없는 난쟁이놈이 전생에 나라라도 구했는지 ㅋㅋ 천운을 탔구나...  계속 깝치는 모습보니 안경벗기고 스크류 드라이버로 눈쑤셔버리고 싶다.'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi3uWMfsm9wK",
        "outputId": "9e097d0f-6207-484c-acb6-1eec2f7c2105"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "요목조목 다 따져봐도 특출나게 잘난것도 없는 난쟁이놈이 전생에 나라라도 구했는지 ㅋㅋ 천운을 탔구나...  계속 깝치는 모습보니 안경벗기고 스크류 드라이버로 눈쑤셔버리고 싶다. 가 입력되었으며,\n",
            "모델은 이 문장을 99.92628693580627% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "요목조목 다 따져봐도 특출나게 잘난것도 없는 ***** 전생에 **** 구했는지 ㅋㅋ 천운을 탔구나... 계속 *** 모습보니 안경벗기고 스크류 드라이버로 ****** 싶다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이게 돈이면 다 되는 대한민국 클라쓰쥐~~~~~!!!!!'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDKKcBnKnJpM",
        "outputId": "2c8aeb78-d9af-4b6c-8732-060172925514"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이게 돈이면 다 되는 대한민국 클라쓰쥐~~~~~!!!!! 가 입력되었으며,\n",
            "모델은 이 문장을 55.15960454940796% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "이게 돈이면 다 되는 대한민국 클라쓰쥐~~~~~!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_nkTfN1r6jF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}